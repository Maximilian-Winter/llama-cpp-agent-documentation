# Introduction

The llama-cpp-agent framework is a tool designed to simplify interactions with Large Language Models (LLMs). It provides an interface for chatting with LLMs, executing function calls, generating structured output, performing retrieval augmented generation, and processing text using agentic chains with tools. The framework integrates seamlessly with the llama.cpp server, llama-cpp-python and OpenAI endpoints that support grammar, offering flexibility and extensibility.

## Key Features
- **Simple Chat Interface**: Engage in seamless conversations with LLMs.
- **Structured Output**: Generate structured output (objects) from LLMs.
- **Single and Parallel Function Calling**: Execute functions using LLMs.
- **RAG - Retrieval Augmented Generation**: Perform retrieval augmented generation with colbert reranking.
- **Agent Chains**: Process text using agent chains with tools, supporting Conversational, Sequential, and Mapping Chains.
- **Compatibility**: Works with llama-index tools and OpenAI tool schemas.
- **Flexibility**: Suitable for various applications, from casual chatting to specific function executions.

## Key concepts

- **Agents**: Autonomous entities that can interact with the environment, perform tasks, and make decisions based on their goals and capabilities.
- **Prompts**: Text-based instructions or queries provided to the LLM to guide its output generation.
- **Functions**: Predefined operations or tasks that can be executed by the LLM based on the input prompt.
- **Tools**: External resources or APIs that can be leveraged by the LLM to enhance its capabilities and perform specific tasks.
- **Chains**: Sequences of actions or steps performed by the LLM to accomplish a complex task, often involving the use of multiple tools or functions.
- **Embeddings**: Numerical representations of text that capture semantic meaning and enable similarity comparisons and retrieval.
- **Vectorization**: The process of converting text into numerical embeddings for efficient storage, retrieval, and comparison.
- **Retrieval**: The act of searching and retrieving relevant information from a knowledge base or external sources based on the input query.
- **Reranking**: The process of refining and reordering search results based on additional criteria or relevance scores to improve the quality of the retrieved information.

These key concepts form the foundation of the llama-cpp-agent framework, enabling developers to create powerful and flexible applications that leverage the capabilities of Large Language Models. By understanding and utilizing these concepts effectively, developers can build intelligent agents, conversational interfaces, and task-oriented systems that can understand and respond to natural language input, execute functions, retrieve relevant information, and generate structured output.

## Guides

Jump into one of our guides to learn more:

### Simple Chat Example using llama.cpp server backend
This example demonstrates how to initiate a chat with an LLM model using the llama.cpp server backend. It supports llama-cpp-python Llama class instances, OpenAI endpoints with GBNF grammar support, and the llama.cpp backend server.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/simple-chat-example/)

### Parallel Function Calling Agent Example
This example showcases parallel function calling using the FunctionCallingAgent class. It demonstrates how to define and execute multiple functions concurrently.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/parallel_function_calling/)

### Structured Output
This example illustrates how to generate structured output objects using the StructuredOutputAgent class. It shows how to create a dataset entry of a book from unstructured data.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/structured-output-example/)

### RAG - Retrieval Augmented Generation
This example demonstrates Retrieval Augmented Generation (RAG) with colbert reranking. It requires installing the optional rag dependencies (ragatouille).

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/rag/)

### llama-index Tools Example
This example shows how to use llama-index tools and query engines with the FunctionCallingAgent class.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/llama_index_tool_use/)

### Sequential Chain Example
This example demonstrates how to create a complete product launch campaign using a sequential chain.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/sequential_chain/)

### Mapping Chain Example
This example illustrates how to create a mapping chain to summarize multiple articles into a single summary.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/map_chain/)

### Knowledge Graph Creation Example
This example, based on an example from the Instructor library for OpenAI, shows how to create a knowledge graph using the llama-cpp-agent framework.

[View Example](https://llama-cpp-agent.readthedocs.io/en/latest/knowledge-graph-example/)